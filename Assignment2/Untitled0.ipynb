{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"116lNz780rvcGcZyYznNOEIC__gCvabWR","authorship_tag":"ABX9TyMe9o0hWLTKU+wIyGTrmVV+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"ytNZ6w3ycfMZ","executionInfo":{"status":"ok","timestamp":1757183308158,"user_tz":-330,"elapsed":20,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c88c8f5","executionInfo":{"status":"ok","timestamp":1757183316817,"user_tz":-330,"elapsed":8643,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"2705229c-b086-4e18-f078-1d283c97d627"},"source":["!pip install keras_applications"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras_applications\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from keras_applications) (2.0.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras_applications) (3.14.0)\n","Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras_applications\n","Successfully installed keras_applications-1.0.8\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n"],"metadata":{"id":"jtjD2wWndF9K","executionInfo":{"status":"ok","timestamp":1757183341152,"user_tz":-330,"elapsed":15,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dataset_path = \"/content/drive/MyDrive/TY VIIT/SEM V/DL/Assignments/Assignment 2/dataset\"\n"],"metadata":{"id":"D4DJ86T8SuQL","executionInfo":{"status":"ok","timestamp":1757183513642,"user_tz":-330,"elapsed":6,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.2,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")\n"],"metadata":{"id":"YiPxa9wRiQ41","executionInfo":{"status":"ok","timestamp":1757183525156,"user_tz":-330,"elapsed":6,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_gen = train_datagen.flow_from_directory(\n","    dataset_path,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode=\"binary\",\n","    subset=\"training\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKus7AN9ivKY","executionInfo":{"status":"ok","timestamp":1757183534689,"user_tz":-330,"elapsed":206,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"16c8ce43-23a8-479a-d072-20cd28c66791"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7571 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["val_gen = train_datagen.flow_from_directory(\n","    dataset_path,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode=\"binary\",\n","    subset=\"validation\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMdIu-atlit6","executionInfo":{"status":"ok","timestamp":1757183543472,"user_tz":-330,"elapsed":223,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"38976232-ef53-40cc-9341-232a87c2187f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1892 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n","base_model.trainable = False\n","\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dropout(0.5),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQJMGT53TQaJ","executionInfo":{"status":"ok","timestamp":1757183559036,"user_tz":-330,"elapsed":4071,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"327c5c62-6501-4725-b22c-7f5389bd846a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["history = model.fit(train_gen, validation_data=val_gen, epochs=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vy0bDbVoTTRY","executionInfo":{"status":"ok","timestamp":1757185874709,"user_tz":-330,"elapsed":2305386,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"388d4db6-50da-4f3d-eef1-8655e29081b9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m237/237\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1719s\u001b[0m 7s/step - accuracy: 0.9068 - loss: 0.2046 - val_accuracy: 0.9995 - val_loss: 0.0126\n","Epoch 2/5\n","\u001b[1m237/237\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 582ms/step - accuracy: 0.9978 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0061\n","Epoch 3/5\n","\u001b[1m237/237\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 576ms/step - accuracy: 0.9994 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0055\n","Epoch 4/5\n","\u001b[1m237/237\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 633ms/step - accuracy: 0.9989 - loss: 0.0061 - val_accuracy: 0.9989 - val_loss: 0.0049\n","Epoch 5/5\n","\u001b[1m237/237\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 575ms/step - accuracy: 0.9998 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0032\n"]}]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/TY VIIT/SEM V/DL/Assignments/Assignment 2/human_vs_nonhuman.h5')\n","print(\"Model saved to google drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjEdSf29Ts58","executionInfo":{"status":"ok","timestamp":1757186132691,"user_tz":-330,"elapsed":371,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"a3485108-6004-4352-bbfa-3d33d6cd02e8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Model saved to google drive\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","\n","# Load model\n","model = load_model(\"/content/drive/MyDrive/TY VIIT/SEM V/DL/Assignments/Assignment 2/human_vs_nonhuman.h5\")\n","\n","# Load and preprocess image\n","img_path = \"/content/drive/MyDrive/TY VIIT/SEM V/DL/Assignments/Assignment 2/dataset/humans/Jennie_Garth_0001.jpg\"\n","img = cv2.imread(img_path)\n","img = cv2.resize(img, (224, 224))\n","img = img.astype(\"float32\") / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","# Predict\n","pred = model.predict(img)[0][0]\n","if pred > 0.5:\n","    print(\"ğŸ‘¤ Person Detected\")\n","else:\n","    print(\"ğŸš« Non-Person Detected\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6Xs6L-WTWxu","executionInfo":{"status":"ok","timestamp":1757186383561,"user_tz":-330,"elapsed":21285,"user":{"displayName":"MANSI MAHABDI","userId":"13763726908150915149"}},"outputId":"8a5842d5-6374-4ea5-8ce2-47702fdb009f"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n","ğŸš« Non-Person Detected\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CnQRLXFSc7Eg"},"execution_count":null,"outputs":[]}]}